# OCI Generative AI Chatbot Deployment

This repository demonstrates a practical chatbot deployment on Oracle Cloud Infrastructure (OCI) as part of the Oracle Cloud Infrastructure Generative AI Professional course. The course is designed for Software Developers, Machine Learning/AI Engineers, and Generative AI Professionals, covering topics such as pretrained foundational models, summarization, embeddings, Dedicated AI Clusters, and the OCI Generative AI security architecture.

## Course Overview

In this course, I learned how to enhance the chatbot's conversational abilities by integrating memory and implementing Retrieval-Augmented Generation (RAG) with LangChain. Additionally, I gained experience in deploying the chatbot on an OCI compute instance.

### The skills that i learned

1. **Fundamentals of Large Language Models (LLMs):**
   - LLM Basics
   - LLM Architectures
   - Prompt Engineering
   - Fine-tuning Techniques
   - Fundamentals of Code Models
   - Multi-modal LLMs and Language Agents

2. **OCI Generative AI Deep Dive:**
   - Pretrained Foundational Models (Generation, Summarization, Embedding)
   - Flexible Fine-tuning (including T-Few technique)
   - Model Inference
   - Dedicated AI Clusters
   - Generative AI Security Architecture

3. **Building a Conversational Chatbot with OCI Generative AI:**
   - Understanding Retrieval-Augmented Generation (RAG)
   - Vector Databases and Semantic Search
   - Building a Chatbot using the LangChain Framework (Prompts, Models, Memory, Chains)
   - Tracing and Evaluating the Chatbot
   - Deploying the Chatbot on OCI

## Step-by-Step Guide

In this repository, I will demonstrate step-by-step how to build an OCI Generative AI chatbot and deploy it on OCI. The guide will cover:

1. Setting up the OCI environment.
2. Building and configuring the chatbot.
3. Implementing memory and RAG using LangChain.
4. Deploying the chatbot on an OCI compute instance.
5. Testing and evaluating the chatbot's performance.



